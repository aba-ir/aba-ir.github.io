<!DOCTYPE html>
<html>
<meta property='og:title' content='GigaGAN for Text-to-Image Synthesis. CVPR2023'/>
<meta property='og:image' content='https://mingukkang.github.io/GigaGAN/static/images/thumbnail.jpg'/>
<meta property='og:description' content='a 1B parameter large scale GAN for text-to-image synthesis task. CVPR2023'/>
<meta property='og:url' content='https://mingukkang.github.io/GigaGAN/'/>
<meta property='og:image:width' content='1200' />
<meta property='og:image:height' content='663' />
<!-- TYPE BELOW IS PROBABLY: 'website' or 'article' or look on https://ogp.me/#types -->
<meta property="og:type" content='website'/>
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9VZKE74FPW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9VZKE74FPW');
</script>
  <meta charset="utf-8">
  <meta name="description"
        content="Scaling up GANs for Text-to-Image Synthesis">
  <meta name="keywords" content="GigaGAN, Text-to-Image, GAN, Image synthesis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ABAIR</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/tab_gallery.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="/static/images/favicon.ico">
  <link rel="stylesheet" href="juxtapose/css/juxtapose.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/magnifier.js"></script>
  <link href="https://fonts.cdnfonts.com/css/menlo" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/image_card_fader.css">
  <link rel="stylesheet" href="./static/css/image_card_slider.css">

</head>

<style>
  @import url('https://fonts.cdnfonts.com/css/menlo');
</style>


<body>
  <section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Adaptive Blind All-in-One Image Restoration</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://davidserra9.github.io/">David Serrano-Lozano</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="http://www.lherranz.org/">Luis Herranz</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=hvzOCpAAAAAJ&hl=ca&oi=ao">Shaolin Su</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://jvazquezcorral.github.io/">Javier Vazquez-Corral</a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Computer Vision Center,</span>
            <span class="author-block"><sup>2</sup>Universitat Autònoma de Barcelona,</span>
            <span class="author-block"><sup>3</sup>Universidad Autónoma de Madrid</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2303.05511"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/mingukkang/GigaGAN/tree/main/evaluation"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <h2 class="title is-3">Adapting to diverse degradations for blind all-in-one IR</h2>
      <div class="has-text-justified">
      <p>
        Our Adaptive Blind All-in-One Image Restoration (ABAIR) model combines a powerful baseline trained on images with synthetic degradations, low-rank decompositions for task-specific adaptation, and a lightweight estimator to handle complex distortions. It achieves state-of-the-art performance on multiple benchmarks while remaining efficient and highly adaptable.
      </p>
      <br>
      </div>
      <!-- The expanding image container -->
      <div class="tab_container">
        <!-- Close the image -->
        <!-- <span onclick="this.parentElement.style.display='none'" class="closebtn">&times;</span> -->

        <!-- Expanded image -->
        <div id="juxtapose-embed" data-startingposition="30%" data-animate="true">
        </div>

        <div>
          <div id="juxtapose-hidden"></div>
        </div>
        
        <!-- Image text -->
        <div id="imgtext"></div>
      </div>

      <!-- The grid: four columns -->
      <div class="tab_row">
        <div class="tab_column">
          <img src="./static/images/plate_blur_input.jpg"  onclick="tab_gallery_click('plate_blur');">

        </div>
        <div class="tab_column">
          <img src="./static/images/pool_lowlight_input.jpg" onclick="tab_gallery_click('pool_lowlight');">
        </div>
        <div class="tab_column">
          <img src="./static/images/airplane_noise_input.jpg" onclick="tab_gallery_click('airplane_noise');">
        </div>
        <div class="tab_column">
          <img src="./static/images/sheep_rain_input.jpg"  onclick="tab_gallery_click('sheep_rain');">
        </div>
        <div class="tab_column">
          <img src="./static/images/street_haze_input.jpg"  onclick="tab_gallery_click('street_haze');">
        </div>
        <div class="tab_column">
          <img src="./static/images/mall_blur_input.jpg"  onclick="tab_gallery_click('mall_blur');">
        </div>
        <div class="tab_column">
          <img src="./static/images/basket_lowlight_input.jpg"  onclick="tab_gallery_click('basket_lowlight');">
        </div>
        <div class="tab_column">
          <img src="./static/images/horses_rain_input.jpg"  onclick="tab_gallery_click('horses_rain');">
        </div>
        <div class="tab_column">
          <img src="./static/images/city_haze_input.jpg"  onclick="tab_gallery_click('city_haze');">
        </div>
        <div class="tab_column">
          <img src="./static/images/trevi_blur_input.jpg"  onclick="tab_gallery_click('trevi_blur');">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  
  <div class="container is-max-desktop">
  
  <!-- Latent space editing applications -->
  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-3">ABAIR architecture</h2>
      <br>
      <!-- Prompt Interpolation image -->      
      <div class="content has-text-centered">
          <img src="./static/images/architecture_overview.svg">
      </div>
      <div class="content has-text-justified">
        <p>
          Our method comprises three key components: a <b>baseline model</b>, a set of <b>Low-Rank Adapters</b>, and a <b>lightweight estimator</b>. First, the baseline model is trained on a large dataset of natural images with synthetically generated degradations, including noise, blur, rain, haze, and low-light conditions. To enhance diversity, we introduce a CutMix strategy to blend multiple degradation types within a single image, paired with a Cross Entropy Loss for pixel-wise degradation classification. Second, the baseline model is adapted to each task using Low-Rank Decomposition (LoRA). Third, a lightweight estimator is trained to identify the input degradations. This estimator enables either the blending or selection of the most suitable adapters to fine-tune the pre-trained baseline weights. Consequently, our method is highly flexible, generalizing effectively to unseen image restoration tasks, mixed degradations, and new tasks. Notably, adapting to new tasks requires only training a new adapter and updating the estimator, without compromising the knowledge gained from previously trained tasks.
        </p>
      </div>
      <br>
    </div>
  </div>    
</div>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Pre-training with Synthetic Degradations</h2>

      <div class="content has-text-justified">
        <p>
          We propose a pre-training strategy based on synthetic degradations, which are parameterized to control both the type and severity of degradations, including rain, blur, noise, haze, and low-light conditions. Furthermore, we introduce a CutMix-based approach to seamlessly integrate multiple degradation types and severity levels within the same image.
        </p>
      </div>

      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-rain">
          <video poster="" id="rain" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/synthetic_rain.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-blur">
          <video poster="" id="blur" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/synthetic_blur.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-noise">
          <video poster="" id="noise" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/synthetic_noise.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-haze">
          <video poster="" id="haze" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/synthetic_haze.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-lowlight">
          <video poster="" id="lowlight" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/synthetic_lol.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Simple yet adaptive method</h2>

      <div class="content has-text-justified">
        <p>
          Our approach is highly effective at handling known degradations while remaining adaptable to new image restoration tasks, enabled by its ability to learn a disentangled representation for each degradation type. In contrast, current methods require retraining the entire architecture with all degradation types to accomodate a new task, making them computationally expensive and inefficient. By using a using a robust baseline model and a disentangled representation, our method requires only training only a small set of parameters for new tasks, preserving the knowledge acquired from previous degradations.
        </p>
      </div>
      <div class="item item-haze">
        <video poster="" id="overview" autoplay controls muted loop height="100%">\
          <!-- Your video file here -->
          <source src="static/videos/adaptive_approach.mp4"
          type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Blind all-in-one image restoration models aim to recover a high-quality image from an input degraded with unknown distortions. However, these models require all the possible degradation types to be defined during the training stage while showing limited generalization to unseen degradations, which limits their practical application in complex cases. In this paper, we propose a simple but effective adaptive blind all-in-one restoration (ABAIR) model, which can address multiple degradations, generalizes well to unseen degradations, and efficiently incorporate new degradations by training a small fraction of parameters. First, we train our baseline model on a large dataset of natural images with multiple synthetic degradations, augmented with a segmentation head to estimate per-pixel degradation types, resulting in a powerful backbone able to generalize to a wide range of degradations. Second, we adapt our baseline model to varying image restoration tasks using independent low-rank adapters. Third, we learn to adaptively combine adapters to versatile images via a flexible and lightweight degradation estimator. Our model is both powerful in handling specific distortions and flexible in adapting to complex tasks, it not only outperforms the state-of-the-art by a large margin on five- and three-task IR setups, but also shows improved generalization to unseen degradations and also composite distortions.
          </p>
        </div>

        <h2 class="title is-3">Quantitative results</h2>
        <div class="content has-text-justified">
          <p>
            We evaluate ABAIR on a five-degradation setup for all-in-one image restoration. Additionally, we assess our method on a three-degradation setup, unseen datasets excluded from training, novel degradation types, and mixed degradation scenarios. The results of our approach, compared to the previous state-of-the-art methods, are summarized in the table below. For more detailed quantitative results, please refer to our paper.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/qualitative_results.png">
        </div>

      </div>
    </div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title"><a id="bibtex">BibTeX</a></h2>
    <pre><code>@inproceedings{serrano2024abair,
  author    = {Serrano-Lozano, David and Herranz, Luis and Su, Shaolin and Vazquez-Corral, Javier},
  title     = {Adaptive Blind All-in-One Image Restoration},
  booktitle = {arXiv preprint},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website adapted from the <a href="https://github.com/mingukkang/GigaGAN/tree/main">GigaGAN</a> and  <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> websites.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


<script src="juxtapose/js/juxtapose.js"></script>

<script>
var slider;
let origImages = [
  {"src": "./static/images/trevi_blur_input.jpg", "label": "Input Degraded Image",},
  {"src": "./static/images/trevi_blur_output.jpg", "label": "Restored by ABAIR",}
];
let origOptions = {
    "makeResponsive": true,
    "showLabels": true,
    "mode": "horizontal",
    "showCredits": true,
    "animate": true,
    "startingPosition": "50"
};

const juxtaposeSelector = "#juxtapose-embed";
const transientSelector = "#juxtapose-hidden";


function tab_gallery_click(name) {
  // Get the expanded image
  let inputImage = {
    label: "Input Degraded Image",
  };
  let outputImage = {
    label: "Restored by ABAIR",
  };

  inputImage.src = "./static/images/".concat(name, "_input.jpg")
  outputImage.src = "./static/images/".concat(name, "_output.jpg")

  let images = [inputImage, outputImage];
  let options = slider.options;
  options.callback = function(obj) {
      var newNode = document.getElementById(obj.selector.substring(1));
      var oldNode = document.getElementById(juxtaposeSelector.substring(1));
      console.log(obj.selector.substring(1));
      console.log(newNode.children[0]);
      oldNode.replaceChild(newNode.children[0], oldNode.children[0]);
      //newNode.removeChild(newNode.children[0]);
      
  };
  
  slider = new juxtapose.JXSlider(transientSelector, images, options);
};



(function() {
    slider = new juxtapose.JXSlider(
        juxtaposeSelector, origImages, origOptions);
    //document.getElementById("left-button").onclick = replaceLeft;
    //document.getElementById("right-button").onclick = replaceRight;
})();
  // Get the image text
  var imgText = document.getElementById("imgtext");
  // Use the same src in the expanded image as the image being clicked on from the grid
  // expandImg.src = imgs.src;
  // Use the value of the alt attribute of the clickable image as text inside the expanded image
  imgText.innerHTML = name;
  // Show the container element (hidden with CSS)
  // expandImg.parentElement.style.display = "block";

$(".flip-card").click(function() {
            console.log("fading in")
            div_back = $(this).children().children()[1]
            div_front = $(this).children().children()[0]
            // console.log($(this).children("div.flip-card-back"))
            console.log(div_back)
            $(div_front).addClass("out");
            $(div_front).removeClass("in");

            $(div_back).addClass("in");
            $(div_back).removeClass("out");

});

$(".flip-card").mouseleave(function() {
            console.log("fading in")
            div_back = $(this).children().children()[1]
            div_front = $(this).children().children()[0]
            // console.log($(this).children("div.flip-card-back"))
            console.log(div_back)
            $(div_front).addClass("in");
            $(div_front).removeClass("out");

            $(div_back).addClass("out");
            $(div_back).removeClass("in");

});

</script>
<!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js" type="text/javascript"></script> -->
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js"></script>    

</body>
</html>
